{
  "project_name": "data_science_project",
  "structure": [
    {
      "type": "file",
      "name": "README.md",
      "content": "# Data Science Project\n\nA data science project with Jupyter notebooks and Python scripts.\n\n## Project Structure\n- `data/`: Raw and processed data\n- `notebooks/`: Jupyter notebooks for analysis\n- `src/`: Source code for data processing and modeling\n- `reports/`: Analysis reports and visualizations\n\n## Setup\n```bash\n# Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: .\\venv\\Scripts\\activate\n\n# Install dependencies\npip install -r requirements.txt\n\n# Install Jupyter kernel\npip install ipykernel\npython -m ipykernel install --user --name=venv\n```"
    },
    {
      "type": "file",
      "name": "requirements.txt",
      "content": "# Core\nnumpy>=1.21.0\npandas>=1.3.0\nmatplotlib>=3.4.0\nseaborn>=0.11.0\n\n# Data processing\nscikit-learn>=1.0.0\nscipy>=1.7.0\n\n# Jupyter\njupyter>=1.0.0\nnb_black>=0.3.0\n\n# Code quality\nblack>=21.0\nflake8>=3.9.0\n\n# Testing\npytest>=6.2.0"
    },
    {
      "type": "file",
      "name": ".gitignore",
      "content": "# Python\n__pycache__/\n*.py[cod]\n*$py.class\n\n# Virtual Environment\nvenv/\nenv/\n\n# Jupyter Notebook\n.ipynb_checkpoints\n*/.ipynb_checkpoints/*\n\n# Data files\n*.csv\n*.h5\n*.hdf5\n*.pkl\n*.pkl.gz\n*.parquet\n*.feather\n\n# Logs and databases\n*.log\n*.sql\n*.sqlite\n\n# IDE\n.idea/\n.vscode/\n*.swp\n*.swo"
    },
    {
      "type": "directory",
      "name": "data",
      "children": [
        {
          "type": "file",
          "name": "raw",
          "content": "# Raw data directory\n# Add raw data files here"
        },
        {
          "type": "file",
          "name": "processed",
          "content": "# Processed data directory\n# Add processed data files here"
        },
        {
          "type": "file",
          "name": "external",
          "content": "# External data sources\n# Add external data files here"
        }
      ]
    },
    {
      "type": "directory",
      "name": "notebooks",
      "children": [
        {
          "type": "file",
          "name": "01_exploratory_analysis.ipynb",
          "content": "{\n \"cells\": [\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"# Exploratory Data Analysis\n    \n    \n    \"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": null,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import pandas as pd\\n\n    \\n    \n    \"\n   ]\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"name\": \"python\",\n   \"version\": \"3.8.0\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}"
        }
      ]
    },
    {
      "type": "directory",
      "name": "src",
      "children": [
        {
          "type": "file",
          "name": "__init__.py",
          "content": "# Initialize src package"
        },
        {
          "type": "file",
          "name": "data",
          "content": "# Data processing utilities\n\nimport pandas as pd\nimport numpy as np\n\ndef load_data(filepath):\n    \"\"\"Load data from file\"\"\"\n    return pd.read_csv(filepath)\n\ndef clean_data(df):\n    \"\"\"Clean the input DataFrame\"\"\"\n    # Add data cleaning steps here\n    return df"
        },
        {
          "type": "file",
          "name": "features",
          "content": "# Feature engineering utilities\n\nimport pandas as pd\n\ndef create_features(df):\n    \"\"\"Create features from raw data\"\"\"\n    # Add feature engineering code here\n    return df"
        },
        {
          "type": "file",
          "name": "models",
          "content": "# Model training and evaluation\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ndef train_model(X, y):\n    \"\"\"Train a machine learning model\"\"\"\n    # Add model training code here\n    pass\n\ndef evaluate_model(model, X_test, y_test):\n    \"\"\"Evaluate model performance\"\"\"\n    # Add model evaluation code here\n    pass"
        },
        {
          "type": "file",
          "name": "visualization",
          "content": "# Visualization utilities\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set style\nsns.set_style(\"whitegrid\")\n\ndef plot_distribution(data, column):\n    \"\"\"Plot distribution of a column\"\"\"\n    plt.figure(figsize=(10, 6))\n    sns.histplot(data[column], kde=True)\n    plt.title(f\"Distribution of {column}\")\n    plt.show()"
        }
      ]
    },
    {
      "type": "directory",
      "name": "reports",
      "children": [
        {
          "type": "file",
          "name": "figures",
          "content": "# Directory for saving figures"
        },
        {
          "type": "file",
          "name": "README.md",
          "content": "# Reports\n\nThis directory contains analysis reports and visualizations.\n\n## Structure\n- `figures/`: Generated plots and visualizations\n- `*.md`: Analysis reports in markdown format"
        }
      ]
    },
    {
      "type": "file",
      "name": "setup.py",
      "content": "from setuptools import setup, find_packages\n\nsetup(\n    name=\"data_science_project\",\n    version=\"0.1.0\",\n    packages=find_packages(),\n    install_requires=[\n        'numpy>=1.21.0',\n        'pandas>=1.3.0',\n        'matplotlib>=3.4.0',\n        'scikit-learn>=1.0.0',\n        'jupyter>=1.0.0',\n    ],\n    python_requires='>=3.8',\n)"
    },
    {
      "type": "file",
      "name": "config.yaml",
      "content": "# Project configuration\n\n# Data paths\ndata:\n  raw: data/raw\n  processed: data/processed\n  external: data/external\n\n# Model parameters\nmodel:\n  test_size: 0.2\n  random_state: 42\n  n_estimators: 100\n  max_depth: 5\n\n# Visualization settings\nviz:\n  style: whitegrid\n  palette: deep\n  dpi: 300\n  figure_format: png"
    }
  ]
}
